{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f05f1f-fb65-470a-8786-34d03a481d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üì¶ TensorFlow version: 2.20.0\n",
      "üì¶ XGBoost version: 3.1.2\n",
      "üéØ Ready to build models!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Model interpretation\n",
    "import shap\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üì¶ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"üì¶ XGBoost version: {xgb.__version__}\")\n",
    "print(f\"üéØ Ready to build models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ecf9ecd-4f1f-4ad6-bca7-69424233dc73",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‚úÖ' (U+2705) (3206852515.py, line 47)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m‚úÖ Loaded SPY: 2517 rows, 35 columns\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '‚úÖ' (U+2705)\n"
     ]
    }
   ],
   "source": [
    "# Load the processed data with technical indicators\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING PROCESSED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define file paths\n",
    "data_path = '../data/processed/'\n",
    "\n",
    "# Load data for all three indices\n",
    "INDICES = ['SPY', 'IWM', 'QQQ']\n",
    "data_dict = {}\n",
    "\n",
    "for ticker in INDICES:\n",
    "    filename = f'{data_path}{ticker}_with_indicators.csv'\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename, index_col=0, parse_dates=True)\n",
    "        data_dict[ticker] = df\n",
    "        print(f\"‚úÖ Loaded {ticker}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    else:\n",
    "        print(f\"‚ùå File not found: {filename}\")\n",
    "        print(f\"   Make sure you completed Phase 3 (Feature Engineering)\")\n",
    "\n",
    "if len(data_dict) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è ERROR: No data files found!\")\n",
    "    print(\"   Please complete Phase 3 first to generate processed data.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Successfully loaded {len(data_dict)} datasets\")\n",
    "    print(f\"üìä Total features available: {data_dict['SPY'].shape[1]}\")\n",
    "```\n",
    "\n",
    "**Run:** Shift + Enter\n",
    "\n",
    "---\n",
    "\n",
    "### üéì **EXPLANATION:**\n",
    "\n",
    "- **Loads data from Phase 3** (data with technical indicators)\n",
    "- **Checks if files exist** before trying to load\n",
    "- **Stores in dictionary** for easy access\n",
    "\n",
    "**Expected Output:**\n",
    "```\n",
    "============================================================\n",
    "LOADING PROCESSED DATA\n",
    "============================================================\n",
    "‚úÖ Loaded SPY: 2517 rows, 35 columns\n",
    "‚úÖ Loaded IWM: 2517 rows, 35 columns\n",
    "‚úÖ Loaded QQQ: 2517 rows, 35 columns\n",
    "\n",
    "‚úÖ Successfully loaded 3 datasets\n",
    "üìä Total features available: 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38584b-61fe-4a2f-ac51-20402f6a25c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a111d0-066e-4950-a756-3fb0f932c42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
